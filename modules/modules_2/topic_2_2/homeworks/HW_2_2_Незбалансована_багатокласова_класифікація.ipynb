{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "У цьому ДЗ ми потренуємось розв'язувати задачу багатокласової класифікації за допомогою логістичної регресії з використанням стратегій One-vs-Rest та One-vs-One, оцінити якість моделей та порівняти стратегії."
   ],
   "metadata": {
    "id": "VUPArbcFJKzJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Опис задачі і даних\n",
    "\n",
    "**Контекст**\n",
    "\n",
    "В цьому ДЗ ми працюємо з даними про сегментацію клієнтів.\n",
    "\n",
    "Сегментація клієнтів – це практика поділу бази клієнтів на групи індивідів, які схожі між собою за певними критеріями, що мають значення для маркетингу, такими як вік, стать, інтереси та звички у витратах.\n",
    "\n",
    "Компанії, які використовують сегментацію клієнтів, виходять з того, що кожен клієнт є унікальним і що їхні маркетингові зусилля будуть більш ефективними, якщо вони орієнтуватимуться на конкретні, менші групи зі зверненнями, які ці споживачі вважатимуть доречними та які спонукатимуть їх до купівлі. Компанії також сподіваються отримати глибше розуміння уподобань та потреб своїх клієнтів з метою виявлення того, що кожен сегмент цінує найбільше, щоб точніше адаптувати маркетингові матеріали до цього сегменту.\n",
    "\n",
    "**Зміст**.\n",
    "\n",
    "Автомобільна компанія планує вийти на нові ринки зі своїми існуючими продуктами (P1, P2, P3, P4 і P5). Після інтенсивного маркетингового дослідження вони дійшли висновку, що поведінка нового ринку схожа на їхній існуючий ринок.\n",
    "\n",
    "На своєму існуючому ринку команда з продажу класифікувала всіх клієнтів на 4 сегменти (A, B, C, D). Потім вони здійснювали сегментовані звернення та комунікацію з різними сегментами клієнтів. Ця стратегія працювала для них надзвичайно добре. Вони планують використати ту саму стратегію на нових ринках і визначили 2627 нових потенційних клієнтів.\n",
    "\n",
    "Ви маєте допомогти менеджеру передбачити правильну групу для нових клієнтів.\n",
    "\n",
    "В цьому ДЗ використовуємо дані `customer_segmentation_train.csv`[скачати дані](https://drive.google.com/file/d/1VU1y2EwaHkVfr5RZ1U4MPWjeflAusK3w/view?usp=sharing). Це `train.csv`з цього [змагання](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation/data?select=train.csv)"
   ],
   "metadata": {
    "id": "7f4tzX6YomVv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 1.** Завантажте та підготуйте датасет до аналізу. Виконайте обробку пропущених значень та необхідне кодування категоріальних ознак. Розбийте на тренувальну і тестувальну вибірку, де в тесті 20%. Памʼятаємо, що весь препроцесинг ліпше все ж тренувати на тренувальній вибірці і на тестувальній лише використовувати вже натреновані трансформери.\n",
    "Але в даному випадку оскільки значень в категоріях небагато, можна зробити обробку і на оригінальних даних, а потім розбити - це простіше. Можна також реалізувати процесинг і тренування моделі з пайплайнами. Обирайте як вам зручніше."
   ],
   "metadata": {
    "id": "NZFXPKx1JX-3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from modules.modules_2.topic_2_1.utils import analyze_dataframe"
   ],
   "metadata": {
    "id": "I-mwGqPS5GAT",
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.193663Z",
     "start_time": "2025-02-02T13:53:03.190551Z"
    }
   },
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.205010Z",
     "start_time": "2025-02-02T13:53:03.196640Z"
    }
   },
   "cell_type": "code",
   "source": "raw_df = pd.read_csv('customer_segmentation_train.csv')",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.263217Z",
     "start_time": "2025-02-02T13:53:03.258246Z"
    }
   },
   "cell_type": "code",
   "source": "raw_df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.325423Z",
     "start_time": "2025-02-02T13:53:03.321404Z"
    }
   },
   "cell_type": "code",
   "source": "analyze_dataframe(raw_df.drop(columns=['ID']))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість рядків: 8068\n",
      "Кількість колонок: 10\n",
      "Кількість числових колонок: 3\n",
      "Кількість категоріальних колонок: 7\n",
      " - Бінарних: 3\n",
      " - Мультикатегоріальних: 4\n",
      "Числові колонки: ['Age', 'Work_Experience', 'Family_Size']\n",
      "Категоріальні колонки: ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1', 'Segmentation']\n",
      "Бінарні колонки: ['Gender', 'Ever_Married', 'Graduated']\n",
      "Мультикатегоріальні колонки: ['Profession', 'Spending_Score', 'Var_1', 'Segmentation']\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.360369Z",
     "start_time": "2025-02-02T13:53:03.353016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Final\n",
    "\n",
    "RANDOM_STATE: Final[int] = 42\n",
    "\n",
    "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=RANDOM_STATE, stratify=raw_df['Segmentation'])\n",
    "\n",
    "# Define input columns and target column\n",
    "input_cols = train_df.columns[1:-1]  # to drop 'ID' and 'Segmentation' columns\n",
    "print('input_cols :', input_cols)\n",
    "\n",
    "target_col: Final[str] = 'Segmentation'\n",
    "print('target_col :', target_col)\n",
    "\n",
    "# Prepare input data for the model\n",
    "train_inputs = train_df[input_cols]\n",
    "train_targets = train_df[target_col]\n",
    "\n",
    "test_inputs = test_df[input_cols]\n",
    "test_targets = test_df[target_col]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_cols : Index(['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
      "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1'],\n",
      "      dtype='object')\n",
      "target_col : Segmentation\n"
     ]
    }
   ],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.392343Z",
     "start_time": "2025-02-02T13:53:03.389957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define numeric and categorical columns\n",
    "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f'{numeric_cols=}')\n",
    "\n",
    "binary_cols = ['Graduated', 'Ever_Married', 'Gender']\n",
    "print(f'{binary_cols=}')\n",
    "\n",
    "binary_cols_without_gender = ['Graduated', 'Ever_Married']\n",
    "print(f'{binary_cols_without_gender=}')\n",
    "\n",
    "gender_col = ['Gender']\n",
    "print(f'{gender_col=}')\n",
    "\n",
    "multi_categorical_cols = ['Profession', 'Spending_Score', 'Var_1']\n",
    "print(f'{multi_categorical_cols=}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_cols=['Age', 'Work_Experience', 'Family_Size']\n",
      "binary_cols=['Graduated', 'Ever_Married', 'Gender']\n",
      "binary_cols_without_gender=['Graduated', 'Ever_Married']\n",
      "gender_col=['Gender']\n",
      "multi_categorical_cols=['Profession', 'Spending_Score', 'Var_1']\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.441922Z",
     "start_time": "2025-02-02T13:53:03.433757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze missing values\n",
    "print(raw_df.isnull().sum())\n",
    "\n",
    "# Analyze categorical columns\n",
    "for col in multi_categorical_cols:\n",
    "    print(f'{col} : {raw_df[col].unique()}')\n",
    "\n",
    "columns = raw_df.select_dtypes(include='object').columns\n",
    "\n",
    "for column in columns:\n",
    "    print(f'Column: {column}')\n",
    "    print(raw_df[column].value_counts())\n",
    "    print(raw_df[column].unique())\n",
    "    print(f'Unique number: {raw_df[column].nunique()}', end='\\n\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                   0\n",
      "Gender               0\n",
      "Ever_Married       140\n",
      "Age                  0\n",
      "Graduated           78\n",
      "Profession         124\n",
      "Work_Experience    829\n",
      "Spending_Score       0\n",
      "Family_Size        335\n",
      "Var_1               76\n",
      "Segmentation         0\n",
      "dtype: int64\n",
      "Profession : ['Healthcare' 'Engineer' 'Lawyer' 'Entertainment' 'Artist' 'Executive'\n",
      " 'Doctor' 'Homemaker' 'Marketing' nan]\n",
      "Spending_Score : ['Low' 'Average' 'High']\n",
      "Var_1 : ['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' nan 'Cat_5']\n",
      "Column: Gender\n",
      "Gender\n",
      "Male      4417\n",
      "Female    3651\n",
      "Name: count, dtype: int64\n",
      "['Male' 'Female']\n",
      "Unique number: 2\n",
      "\n",
      "Column: Ever_Married\n",
      "Ever_Married\n",
      "Yes    4643\n",
      "No     3285\n",
      "Name: count, dtype: int64\n",
      "['No' 'Yes' nan]\n",
      "Unique number: 2\n",
      "\n",
      "Column: Graduated\n",
      "Graduated\n",
      "Yes    4968\n",
      "No     3022\n",
      "Name: count, dtype: int64\n",
      "['No' 'Yes' nan]\n",
      "Unique number: 2\n",
      "\n",
      "Column: Profession\n",
      "Profession\n",
      "Artist           2516\n",
      "Healthcare       1332\n",
      "Entertainment     949\n",
      "Engineer          699\n",
      "Doctor            688\n",
      "Lawyer            623\n",
      "Executive         599\n",
      "Marketing         292\n",
      "Homemaker         246\n",
      "Name: count, dtype: int64\n",
      "['Healthcare' 'Engineer' 'Lawyer' 'Entertainment' 'Artist' 'Executive'\n",
      " 'Doctor' 'Homemaker' 'Marketing' nan]\n",
      "Unique number: 9\n",
      "\n",
      "Column: Spending_Score\n",
      "Spending_Score\n",
      "Low        4878\n",
      "Average    1974\n",
      "High       1216\n",
      "Name: count, dtype: int64\n",
      "['Low' 'Average' 'High']\n",
      "Unique number: 3\n",
      "\n",
      "Column: Var_1\n",
      "Var_1\n",
      "Cat_6    5238\n",
      "Cat_4    1089\n",
      "Cat_3     822\n",
      "Cat_2     422\n",
      "Cat_7     203\n",
      "Cat_1     133\n",
      "Cat_5      85\n",
      "Name: count, dtype: int64\n",
      "['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' nan 'Cat_5']\n",
      "Unique number: 7\n",
      "\n",
      "Column: Segmentation\n",
      "Segmentation\n",
      "D    2268\n",
      "A    1972\n",
      "C    1970\n",
      "B    1858\n",
      "Name: count, dtype: int64\n",
      "['D' 'A' 'B' 'C']\n",
      "Unique number: 4\n",
      "\n"
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.485334Z",
     "start_time": "2025-02-02T13:53:03.482610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing number columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing binary columns\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder())  # same as df['Graduated'].map({'Yes': 1, 'No': 0})\n",
    "])\n",
    "\n",
    "# Preprocessing for column 'Gender' with OneHotEncoder\n",
    "# We use OneHotEncoder to avoid assuming the order of values ('Male' and 'Female')\n",
    "# As for simplicity we could leave it as is and use OrdinalEncoder in binary_transformer, but I want to make it more accurate\n",
    "# since gender could affect the result I suppose.\n",
    "gender_transformer = Pipeline(steps=[\n",
    "    # We don't need imputer here, because there are no missing\n",
    "    ('onehot', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Preprocessing categorical columns\n",
    "multi_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('bin', binary_transformer, binary_cols_without_gender),\n",
    "        ('gender', gender_transformer, gender_col),\n",
    "        ('cat', multi_categorical_transformer, multi_categorical_cols)\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.580796Z",
     "start_time": "2025-02-02T13:53:03.566529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess train data\n",
    "X_train = preprocessor.fit_transform(train_inputs)\n",
    "y_train = train_targets\n",
    "\n",
    "# Preprocess test data\n",
    "X_test = preprocessor.transform(test_inputs)\n",
    "y_test = test_targets"
   ],
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 2. Важливо уважно прочитати все формулювання цього завдання до кінця!**\n",
    "\n",
    "Застосуйте методи ресемплингу даних SMOTE та SMOTE-Tomek з бібліотеки imbalanced-learn до тренувальної вибірки. В результаті у Вас має вийти 2 тренувальних набори: з апсемплингом зі SMOTE, та з ресамплингом з SMOTE-Tomek.\n",
    "\n",
    "Увага! В нашому наборі даних є як категоріальні дані, так і звичайні числові. Базовий SMOTE не буде правильно працювати з категоріальними даними, але є його модифікація, яка буде. Тому в цього завдання є 2 виконання\n",
    "\n",
    "  1. Застосувати SMOTE базовий лише на НЕкатегоріальних ознаках.\n",
    "\n",
    "  2. Переглянути інформацію про метод [SMOTENC](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) і використати цей метод в цій задачі. За цей спосіб буде +3 бали за це завдання і він рекомендований для виконання.\n",
    "\n",
    "  **Підказка**: аби скористатись SMOTENC треба створити змінну, яка містить індекси ознак, які є категоріальними (їх номер серед колонок) і передати при ініціації екземпляра класу `SMOTENC(..., categorical_features=cat_feature_indeces)`.\n",
    "  \n",
    "  Ви також можете розглянути варіант використання варіації SMOTE, який працює ЛИШЕ з категоріальними ознаками [SMOTEN](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTEN.html)"
   ],
   "metadata": {
    "id": "fhJzCBA7P0f8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# SMOTE works only on numeric data\n",
    "# So lets transform it\n",
    "X_numeric = numeric_transformer.fit_transform(train_inputs[numeric_cols])\n",
    "y = train_targets\n",
    "\n",
    "# Create SMOTE instance\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_numeric, y)\n",
    "\n",
    "X_test_smote = numeric_transformer.transform(test_inputs[numeric_cols])\n",
    "\n",
    "original_counts = y.value_counts()\n",
    "resampled_counts = pd.Series(y_train_smote).value_counts()\n",
    "\n",
    "print(\"Було:\")\n",
    "for label, count in original_counts.items():\n",
    "    print(f'Клас {label}: {count}')\n",
    "\n",
    "print(\"\\nСтало:\")\n",
    "for label, count in resampled_counts.items():\n",
    "    print(f'Клас {label}: {count}')"
   ],
   "metadata": {
    "id": "6NFUkQ_15HNX",
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.602129Z",
     "start_time": "2025-02-02T13:53:03.584495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Було:\n",
      "Клас D: 1814\n",
      "Клас A: 1578\n",
      "Клас C: 1576\n",
      "Клас B: 1486\n",
      "\n",
      "Стало:\n",
      "Клас A: 1814\n",
      "Клас B: 1814\n",
      "Клас C: 1814\n",
      "Клас D: 1814\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.889357Z",
     "start_time": "2025-02-02T13:53:03.646073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SMOTENC works on numeric and categorical data (it is not designed to work with only categorical features.)\n",
    "# So lets transform it :)\n",
    "\n",
    "# Get indices of categorical features\n",
    "cols = multi_categorical_cols + binary_cols\n",
    "categorical_features_indices = [train_inputs.columns.get_loc(col) for col in cols]\n",
    "print(cols)\n",
    "print(categorical_features_indices)\n",
    "\n",
    "# Create SMOTENC instance\n",
    "smotenc = SMOTENC(categorical_features=categorical_features_indices, random_state=RANDOM_STATE)\n",
    "X_train_smotenc, y_train_smotenc = smotenc.fit_resample(X_train, y_train)\n",
    "\n",
    "original_counts = y.value_counts()\n",
    "resampled_counts = pd.Series(y_train_smotenc).value_counts()\n",
    "\n",
    "print(\"Було:\")\n",
    "for label, count in original_counts.items():\n",
    "    print(f'Клас {label}: {count}')\n",
    "\n",
    "print(\"\\nСтало:\")\n",
    "for label, count in resampled_counts.items():\n",
    "    print(f'Клас {label}: {count}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Profession', 'Spending_Score', 'Var_1', 'Graduated', 'Ever_Married', 'Gender']\n",
      "[4, 6, 8, 3, 1, 0]\n",
      "Було:\n",
      "Клас D: 1814\n",
      "Клас A: 1578\n",
      "Клас C: 1576\n",
      "Клас B: 1486\n",
      "\n",
      "Стало:\n",
      "Клас A: 1814\n",
      "Клас B: 1814\n",
      "Клас C: 1814\n",
      "Клас D: 1814\n"
     ]
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:03.983064Z",
     "start_time": "2025-02-02T13:53:03.928524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model on Smote-Tomek data\n",
    "smote_tomek = SMOTETomek(random_state=RANDOM_STATE)\n",
    "X_train_smotetomek, y_train_smotetomek = smote_tomek.fit_resample(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": 196
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 3**.\n",
    "  1. Навчіть модель логістичної регресії з використанням стратегії One-vs-Rest з логістичною регресією на оригінальних даних, збалансованих з SMOTE, збалансованих з Smote-Tomek.  \n",
    "  2. Виміряйте якість кожної з натренованих моделей використовуючи `sklearn.metrics.classification_report`.\n",
    "  3. Напишіть, яку метрику ви обрали для порівняння моделей.\n",
    "  4. Яка модель найкраща?\n",
    "  5. Якщо немає суттєвої різниці між моделями - напишіть свою гіпотезу, чому?"
   ],
   "metadata": {
    "id": "ja4w_GgmT4D0"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:04.080315Z",
     "start_time": "2025-02-02T13:53:04.028075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITER = 1000\n",
    "\n",
    "# Model on original data\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, max_iter=MAX_ITER)\n",
    "ovr_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', OneVsRestClassifier(log_reg))\n",
    "])\n",
    "ovr_model.fit(train_inputs, train_targets)\n",
    "ovr_predictions = ovr_model.predict(test_inputs)\n",
    "\n",
    "# Evaluation of the model on original data\n",
    "print(\"Модель на оригінальних даних:\")\n",
    "print(classification_report(test_targets, ovr_predictions))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель на оригінальних даних:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.42      0.46      0.44       394\n",
      "           B       0.42      0.17      0.24       372\n",
      "           C       0.49      0.63      0.55       394\n",
      "           D       0.65      0.76      0.70       454\n",
      "\n",
      "    accuracy                           0.52      1614\n",
      "   macro avg       0.50      0.51      0.48      1614\n",
      "weighted avg       0.50      0.52      0.50      1614\n",
      "\n"
     ]
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:53:06.821271Z",
     "start_time": "2025-02-02T13:53:06.532305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#SMOTENC\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTENC(categorical_features=categorical_features_indices, random_state=RANDOM_STATE)),\n",
    "    ('classifier', OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, max_iter=MAX_ITER)))\n",
    "])\n",
    "\n",
    "pipeline.fit(train_inputs, train_targets)\n",
    "\n",
    "ovr_predictions = pipeline.predict(test_inputs)\n",
    "print(\"Модель на даних зі SMOTENC:\")\n",
    "print(classification_report(y_test, ovr_predictions))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель на даних зі SMOTENC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.42      0.48      0.45       394\n",
      "           B       0.41      0.25      0.31       372\n",
      "           C       0.50      0.59      0.54       394\n",
      "           D       0.68      0.72      0.70       454\n",
      "\n",
      "    accuracy                           0.52      1614\n",
      "   macro avg       0.50      0.51      0.50      1614\n",
      "weighted avg       0.51      0.52      0.51      1614\n",
      "\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:54:01.691951Z",
     "start_time": "2025-02-02T13:54:01.578322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model on SMOTE-Tomek data\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote_tomek', SMOTETomek(random_state=RANDOM_STATE)),\n",
    "    ('classifier', OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, max_iter=MAX_ITER)))\n",
    "])\n",
    "\n",
    "pipeline.fit(train_inputs, train_targets)\n",
    "\n",
    "ovr_predictions = pipeline.predict(test_inputs)\n",
    "print(\"Модель на даних зі SMOTE-Tomek:\")\n",
    "print(classification_report(y_test, ovr_predictions))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель на даних зі SMOTE-Tomek:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.42      0.47      0.44       394\n",
      "           B       0.41      0.25      0.31       372\n",
      "           C       0.50      0.59      0.54       394\n",
      "           D       0.68      0.71      0.69       454\n",
      "\n",
      "    accuracy                           0.52      1614\n",
      "   macro avg       0.50      0.51      0.50      1614\n",
      "weighted avg       0.51      0.52      0.51      1614\n",
      "\n"
     ]
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Висновки:**\n",
    "\n",
    "Клас D: 1814\n",
    "Клас A: 1578\n",
    "Клас C: 1576\n",
    "Клас B: 1486\n",
    "\n",
    "\n",
    "Для порівняння моделей я обрав метрику `f1-score`, оскільки вона враховує як точність, так і повноту моделі. Це дозволяє оцінити якість моделі більш точно, ніж просто за точністю або повнотою.\n",
    "\n",
    "Модель на оригінальних даних показала найгірший результат серед трьох моделей. Проте це не показує, що вона набагато гірше, бо ми бачимо, що коренева різниця лише в предикшині B класу (що в цілому і очікувано, бо у нас в датасеті В класу менше, ніж інших). Тож використовуючи SMOTENC та SMOTE-Tomek ми отримали кращі результати, ніж на оригінальних даних. У нас дані не так, щоб і багато дисбалансовані, проте ми їх збалансували і бачим, що як раз на ось ту різницю +- воно і дало нам покращення.\n",
    "\n",
    "Тепер чому така невелика різниця - я вважаю, що це може бути як раз із-за того, що не така і велика різниця в дизбалансі насправді. Ми бачимо, що класу D у нас найбільше (1814 інстансів), коли найменше - клабу B (1486 інстанстів). Але в моєму тут прикладі такий цікавий ефект, що якщо подивитись на інші метрики як recall & f1, то для класу D там на 0.01 менше значення у SMOTE-Tomek, ніж для SMOTENC. У моєму варіанті я же там окремо Gender опрацював як OneHotEncoder замість OrdinalEncoder, тому можливо це вплинуло на результати."
   ]
  }
 ]
}
